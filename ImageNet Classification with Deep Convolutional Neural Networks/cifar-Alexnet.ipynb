{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import CSVLogger, EarlyStopping\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import  Conv2D, MaxPooling2D, Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters for the training\n",
    "batch_size = 128\n",
    "num_classes = 10 \n",
    "epochs = 100 \n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models') \n",
    "model_name = 'keras_cifar10_trained_model.h5' # Model name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Splits the data between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Converts the vectors to one hot encoding\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#Layer 1 \n",
    "model.add(Conv2D(filters=48, kernel_size=(3,3), \n",
    "                 strides=(1,1), padding='same', \n",
    "                 input_shape=(32,32,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)) )\n",
    "\n",
    "#Layer 2\n",
    "model.add(Conv2D(filters=96, kernel_size=(3,3), padding='same') )\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "#Layer 3\n",
    "model.add(Conv2D(filters=192, kernel_size=(3,3), \n",
    "                  activation='relu', padding='same') )\n",
    "\n",
    "#Layer 4\n",
    "model.add(Conv2D(filters=192, kernel_size=(3,3), \n",
    "                  activation='relu', padding='same') )\n",
    "\n",
    "#Layer 5\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), \n",
    "                 activation='relu', padding='same') )\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)) )\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "#Layer 6\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#Layer 7 \n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#Prediction\n",
    "model.add(Dense(10))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=SGD(lr=0.01, momentum=0.9, decay=0.0005),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 15s 297us/step - loss: 1.7238 - acc: 0.3730 - val_loss: 2.3087 - val_acc: 0.2393\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 12s 248us/step - loss: 1.2773 - acc: 0.5514 - val_loss: 1.2311 - val_acc: 0.5760\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 12s 249us/step - loss: 1.0398 - acc: 0.6421 - val_loss: 2.1019 - val_acc: 0.3609\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 12s 248us/step - loss: 0.9036 - acc: 0.6920 - val_loss: 0.8706 - val_acc: 0.6987\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 12s 247us/step - loss: 0.7919 - acc: 0.7311 - val_loss: 0.9602 - val_acc: 0.6707\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 12s 248us/step - loss: 0.7093 - acc: 0.7618 - val_loss: 0.8095 - val_acc: 0.7258\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 12s 248us/step - loss: 0.6316 - acc: 0.7905 - val_loss: 0.7377 - val_acc: 0.7535\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 12s 248us/step - loss: 0.5684 - acc: 0.8147 - val_loss: 0.8991 - val_acc: 0.6993\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 12s 248us/step - loss: 0.4965 - acc: 0.8384 - val_loss: 0.7954 - val_acc: 0.7353\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 12s 248us/step - loss: 0.4501 - acc: 0.8548 - val_loss: 0.6881 - val_acc: 0.7700\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 12s 248us/step - loss: 0.3885 - acc: 0.8766 - val_loss: 0.7602 - val_acc: 0.7565\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 12s 248us/step - loss: 0.3384 - acc: 0.8930 - val_loss: 0.6980 - val_acc: 0.7810\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 12s 248us/step - loss: 0.2903 - acc: 0.9092 - val_loss: 0.6642 - val_acc: 0.7880\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 12s 248us/step - loss: 0.2561 - acc: 0.9224 - val_loss: 0.6518 - val_acc: 0.7982\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 12s 248us/step - loss: 0.2063 - acc: 0.9402 - val_loss: 0.6490 - val_acc: 0.7976\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 12s 248us/step - loss: 0.1672 - acc: 0.9539 - val_loss: 0.7861 - val_acc: 0.7719\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 12s 248us/step - loss: 0.1407 - acc: 0.9632 - val_loss: 0.6753 - val_acc: 0.8000\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 12s 248us/step - loss: 0.1168 - acc: 0.9706 - val_loss: 0.6500 - val_acc: 0.8086\n",
      "10000/10000 [==============================] - 1s 133us/step\n",
      "Loss: 0.650\n",
      "Accuracy: 0.809\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          shuffle=True,\n",
    "          epochs=100,\n",
    "          validation_data=(x_test, y_test),\n",
    "          callbacks=[EarlyStopping(min_delta=0.001, patience=3)])\n",
    "\n",
    "# Evaluate the model\n",
    "scores = model.evaluate(x_test, y_test)\n",
    "\n",
    "print('Loss: %.3f' % scores[0])\n",
    "print('Accuracy: %.3f' % scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
